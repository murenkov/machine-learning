{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d62b3541-d8f3-49f4-97bc-61c24c13ade7",
   "metadata": {},
   "source": [
    "# Лабораторная работа №2. Линейные модели для задач регрессии\n",
    "\n",
    "В данной лабораторной работе рассматриваются задачи регрессии.\n",
    "Частным случаем является задача линейной регрессии.\n",
    "Используется следующая модель:\n",
    "$$\n",
    "y = \\sum_{k=0}^{M-1} w_k \\phi_k(\\mathbf{x}) = \\mathbf{w}^T \\mathbf{\\phi}(\\mathbf{x}),\n",
    "$$\n",
    "где $\\mathbf{\\phi}(\\mathbf{x}) = \\left(1, \\phi_1(\\mathbf{x}), \\dots, \\phi_{M-1}(\\mathbf{x})\\right)^T$,\n",
    "$\\mathbf{w} = \\left(w_0, w_1, \\dots, w_{M-1}\\right)^T$.\n",
    "\n",
    "В данной работе в качестве функции штрафа используется средняя квадратичная ошибка:\n",
    "$$\n",
    "E_D(\\mathbf{w}, \\mathbf{T}) = \\frac{1}{2} \\sum_{n=1}^{N} \\left( t_n - \\mathbf{w}^T \\mathbf{\\phi}(\\mathbf{x}_n) \\right)^2.\n",
    "$$\n",
    "\n",
    "Решение задачи минимизации такого штрафа даёт параметры распознавателя\n",
    "$$\n",
    "\\mathbf{w_{ML}} = \\left(\\mathbf{\\Phi}^T \\mathbf{\\Phi}\\right)^{-1} \\mathbf{\\Phi}^T \\mathbf{T}.\n",
    "$$\n",
    "\n",
    "В случае добавления $L2$-регуляризации (гребневая регрессия) штраф:\n",
    "$$\n",
    "E(\\mathbf{w}) = \\frac{1}{2} \\sum_{n=1}^{N} \\left( t_n - \\mathbf{w}^T \\mathbf{\\phi}(\\mathbf{x}_n) \\right)^2 + \\frac{\\lambda}{2} \\mathbf{w}^T \\mathbf{w},\n",
    "$$\n",
    "МНК-решением будет\n",
    "$$\n",
    "\\mathbf{w_{ML}} = \\left(\\mathbf{\\Phi}^T \\mathbf{\\Phi} + \\lambda \\mathbf{E} \\right)^{-1} \\mathbf{\\Phi}^T \\mathbf{T}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d7b86a-8989-4a70-9a4b-b4cb9a7dcd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from sklearn import datasets, model_selection, metrics\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mpl.rcParams['axes.grid'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9212a62-39af-46d8-ba73-00336cedeb3c",
   "metadata": {},
   "source": [
    "## Задание №1\n",
    "\n",
    "Реализуйте функцию, которая возвращает параметры модели, найденные с помощью метода наименьших квадратов.\n",
    "Операция умножения в `numpy` - это `np.matmul` или `@`.\n",
    "Перевод массива в тип матрица осуществляется с помощью `np.asmatrix`.\n",
    "Транспонирование матрицы `x` - это операция `x.T`.\n",
    "Получение из матрицы `x` линейный массив - это операция `x.A1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0116747-d7db-40cc-9f8d-339bb79d0008",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeastSquare:\n",
    "    def __init__(self, x, y):\n",
    "        x = ??? np.concatenate\n",
    "        w = ?? np.linalg.inv, a @ b, np.asmatrix(y)\n",
    "        self.??? = ???\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return ??? a @ b, a.A1\n",
    "\n",
    "# Тестирование\n",
    "\n",
    "test_x = np.array([[1, 1, 1], [2, 2**2, 2**3], [3, 3**2, 3**3], [4, 4**2, 4**3]])\n",
    "lsm = LeastSquare(test_x, [-1, 1, 2, 3])\n",
    "assert np.linalg.norm(lsm(test_x) - [-1, 1, 2, 3]) < 1e-9, 'Метод недостаточно точный'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf1c1ab-1cf8-4177-a88d-c0eddab0635e",
   "metadata": {},
   "source": [
    "## Задание №2\n",
    "\n",
    "Сгенерируйте данные для регрессии.\n",
    "Размер выборки определяется соотношением `100 + 50 * mod(<порядковый номер в группе>, 5)`.\n",
    "Разделите полученную выборку на обучающую и тестовую.\n",
    "Размер тестовой выборки должен составлять 20% от размера изначальной выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be95d0f-4907-4afb-bc26-d786996ccfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = sk.datasets.make_regression(n_samples=???, n_features=1, noise=1.5, bias=13, random_state=125)\n",
    "x_train, x_test, y_train, y_test = sk.model_selection.???(???, random_state=25)\n",
    "print(x_train.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5bd449-60eb-4029-bf3a-ed7ba6384e82",
   "metadata": {},
   "source": [
    "Запустите МНК для сгенерированного датасета.\n",
    "Постройте графики, на которых изображены истинные и предсказанные значения, для тестовой и обучающей выборки.\n",
    "Приведите значения MSE-ошибки для обеих выборок на тестовой и обучающей части.\n",
    "$$\n",
    "MSE = \\frac{1}{N} \\sum_{n=0}^{N-1} \\left( t_n - y_n \\right)^2.\n",
    "$$\n",
    "Сравните ошибки на обучающей и тестовой выборках, сделайте выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c82186-03d3-46d9-a2f4-ad0dad604812",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LeastSquare(x_train, y_train)\n",
    "\n",
    "ry_train, ry_test = regressor(x_train), regressor(x_test)\n",
    "fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(2*6, 4))\n",
    "\n",
    "ax0.plot(???, label=???)\n",
    "ax0.plot(???, label=???)\n",
    "ax0.set(xlabel='Отсчёты', ylabel='Значения', title='Обучающая выборка')\n",
    "ax0.legend()\n",
    "\n",
    "ax1.plot???\n",
    "\n",
    "print('Ошибка на обучающей выборке', ??? sk.metrics.mean_squared_error)\n",
    "print('Ошибка на тестовой выборке', ???)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fc46bd-3469-465b-bdaa-873a94147b84",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Задание №3\n",
    "\n",
    "Реализуйте функцию, вычисляющую веса $w$ методом градиентного спуска:\n",
    "$$\n",
    "\\mathbf{w}_{i+1} = \\mathbf{w}_i - \\eta \\nabla E (\\mathbf{w}_i, T),\\; i = 1,2,\\dots , \\\\\n",
    "E(w) = \\frac{1}{2} \\sum_{n=0}^{N-1} \\left( t_n - \\mathbf{w}^T\\mathbf{\\phi}(\\mathbf{x}_n) \\right)^2, \\\\\n",
    "\\nabla E(\\mathbf{w}) = \\mathbf{\\Phi}^T(\\mathbf{\\Phi}\\mathbf{w} - \\mathbf{T}).\n",
    "$$\n",
    "c условием выхода:\n",
    "$$\n",
    "| E_i - E_{i-1} | < \\varepsilon \\; \\mathrm{или} \\; N_{iter} \\ge N_{max},\n",
    "$$\n",
    "где $N_{iter}$ $-$ номер итерации.\n",
    "Здесь полагаем, что $\\mathbf{\\phi}(\\mathbf{x}) = \\mathbf{x}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4108ca1a-1d08-430b-919f-13797ff4dd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientDescent:\n",
    "    def __init__(self, x, y, eta=1e-3, eps=1e-6, n_iter=5000):\n",
    "        self.eta, self.eps, self.n_iter = eta, eps, n_iter\n",
    "        self.w = np.random.uniform(???)\n",
    "\n",
    "        x = ??? np.concatenate\n",
    "        ???\n",
    "        \n",
    "        self.last_iter, self.last_error, self.last_error_delta = n, e, abs(eprev - e)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        return ??? reshape(-1)\n",
    "\n",
    "# Тестирование\n",
    "\n",
    "test_x = np.array([[0, 1, 2], [3, 4, 5]])\n",
    "gd = GradientDescent(test_x, [-1, 1])\n",
    "assert np.linalg.norm(gd(test_x) - [-1, 1]) < 1, 'Метод недостаточно точный'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd5cc03-d26e-47f9-a961-a8a4df8435da",
   "metadata": {},
   "source": [
    "Запустите полученную модель для датасета.\n",
    "Сравните ошибки на выборках, полученные методом градиентного спуска.\n",
    "Выведите количество итераций, за которое модель достигла нужной точности.\n",
    "\n",
    "**Замечание**.\n",
    "Чтобы добиться приемлемых результатов (малого значения MSE), возможно, потребуется подобрать подходящие параметры шага градиентного спуска $\\eta$ и максимального количества итераций. Для начала возьмите:\n",
    "\n",
    "* $w_0 = \\left( {w_0}_0, {w_0}_1, \\dots, {w_0}_{n-1} \\right)$, где каждая компонента ${w_0}_i$ распределена равномерно на отрезке $[-1, 1]$;\n",
    "* $\\eta = 10^{-3}$; \n",
    "* $\\varepsilon = 10^{-6}$;\n",
    "* $N_{max} = 5000$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10098be1-1935-4c37-81fd-73cba168d086",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = GradientDescent(x_train, y_train)\n",
    "ry_train, ry_test = ???\n",
    "fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(2*6, 4))\n",
    "\n",
    "ax0.plot(???)\n",
    "???\n",
    "\n",
    "ax1.plot(???)\n",
    "???\n",
    "\n",
    "print('Ошибка на обучающей выборке', ???)\n",
    "print('Ошибка на тестовой выборке', ???)\n",
    "#print('Статистика:', regressor.last_iter, regressor.last_error, regressor.last_error_delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243e76e7-a52d-4a28-813c-e4dd72296964",
   "metadata": {},
   "source": [
    "**Вопросы**:\n",
    "\n",
    "1. Стали ли результаты лучше метода наименьших квадратов из предыдущего пункта?\n",
    "1. Как параметр $\\eta$ влияет на количество итераций?\n",
    "1. Найдите примерное значение $\\eta$, после которого метод расходится (ошибка возрастает, а не уменьшается)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1217aa1-6b4f-473a-adf6-c9e25d222af6",
   "metadata": {},
   "source": [
    "**Ответы:**\n",
    "\n",
    "1. ...\n",
    "1. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3abe83-84d7-4834-aa6a-f545c5563ff6",
   "metadata": {},
   "source": [
    "## Задание №4\n",
    "\n",
    "Сгенерируйте датасет с нелинейными данными:\n",
    "\n",
    "* $x$ - это вектор из 15 элементов, значения которого распределены равномерно на интервале $[-1; 1]$;\n",
    "* $y$ - это синусоида от значений $x$, смещенных на $0.7$, к которой прибавлен шум в виде нормального распределения $N(0.1, 0.2)$;\n",
    "* выделите из полученных данных обучающую и тестовую выборки.\n",
    "Размер тестовой выборки составляет 20%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c64cd19-d8b0-44d9-9ff5-16d90c79c06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=4)\n",
    "x = rng.???\n",
    "y = ??? reshape(-1)\n",
    "plt.scatter(x, y)\n",
    "\n",
    "x_train, x_test, y_train, y_test = ??? random_state=43\n",
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3398498-ad82-408f-8939-08f7d25d7fbf",
   "metadata": {},
   "source": [
    "Примените один из предыдущих методов на полученном датасете.\n",
    "Постройте гистограмму ошибок предсказания, полученных на обучающих и тестовых данных.\n",
    "Дайте оценку качеству предсказания, оценивая его по величине MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0a3cf8-ff13-4d6f-bb01-72b3ddbc4382",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = ???(x_train, y_train)\n",
    "\n",
    "fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(2*6, 4))\n",
    "ax0.hist(abs(regressor(x_train) - y_train))\n",
    "ax0.set(xlabel='Величина ошибки', ylabel='Количество', title='Обучающая выборка')\n",
    "ax1.hist(???)\n",
    "???\n",
    "\n",
    "print('Ошибка на обучающей выборке:', ???)\n",
    "print('Ошибка на тестовой выборке:', ???)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebebc65-4661-41dc-989e-68961b5c2cfb",
   "metadata": {},
   "source": [
    "## Задание №5\n",
    "\n",
    "Создайте функцию-декоратор для добавления степенной зависимости в произвольную модель регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fb9c83-4d63-4832-9bb7-9e29315791ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PolyDecorator(clazz, *args, **kwargs):\n",
    "    class PolyDecoratorClass(clazz):\n",
    "        def __init__(self, p, x, *args):\n",
    "            super().__init__(PolyDecoratorClass.poly(x, p), *args)\n",
    "            self.p = p\n",
    "        \n",
    "        def __call__(self, x):\n",
    "            return super().__call__(PolyDecoratorClass.poly(x, self.p))\n",
    "        \n",
    "        @staticmethod\n",
    "        def poly(x, k):\n",
    "            return np.concatenate([??? for p in range(1, k + 1)], axis=1)\n",
    "\n",
    "    return PolyDecoratorClass(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeed73be-0bfc-44f5-9dd3-19cb9844ceb9",
   "metadata": {},
   "source": [
    "Попробуйте улучшить результат для датасета.\n",
    "Используйте модель\n",
    "$$\n",
    "y_{pred} = w_0 + w_1 x + w_2 x^2 + \\dots + w_p x^p.\n",
    "$$\n",
    "\n",
    "Рассмотрите полиномы порядков $p$ от 1 до 9.\n",
    "\n",
    "Как порядок влияет на качество?\n",
    "Чтобы ответить на этот вопрос, нужно привести значения MSE для обучающей и тестовой выборок в виде графика\n",
    "(зависимость MSE-ошибки $E$ от порядка полинома $p$).\n",
    "Выберите наилучшую модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91e8ecd-2af0-4ed0-86db-344078fcc944",
   "metadata": {},
   "outputs": [],
   "source": [
    "powers = np.arange(1, 10)\n",
    "train_err, test_err, regr = [], [], []\n",
    "for p in powers:\n",
    "    regressor = PolyDecorator(???, p, x_train, y_train)\n",
    "    train_err???\n",
    "    test_err???\n",
    "    regr???\n",
    "\n",
    "fig, ax = plt.subplots(???)\n",
    "ax.plot(powers, ???, label='train')\n",
    "ax.plot(powers, ???)\n",
    "ax.set(xlabel='Отсчёты', ylabel='Значения', title='Ошибка предсказания')\n",
    "ax.legend()\n",
    "\n",
    "k = ??? test_err\n",
    "fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(2*6, 4))\n",
    "ax0.hist(???)\n",
    "???\n",
    "\n",
    "print(f\"Порядок: {???}, ошибка на тестовой выборке: {???}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5372c4b-64ab-4a8f-971c-ca43f7cff741",
   "metadata": {},
   "source": [
    "**Вопросы:**\n",
    "\n",
    "1. Удалось ли с полиномиальной регрессией достичь лучших результатов, чем с линейной регрессией?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0b4d7f-cbee-4aba-899a-9ee734d47183",
   "metadata": {},
   "source": [
    "**Ответы:**\n",
    "\n",
    "1. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33480ae-7525-43b7-ad90-e4cea9412236",
   "metadata": {},
   "source": [
    "## Задание №6\n",
    "\n",
    "Добавьте $L2$-регуляризацию для модели из пункта 5\n",
    "$$\n",
    "E_r = \\frac{1}{2} \\sum_{n=0}^{N-1} \\left( t_n - \\mathbf{w}^T \\mathbf{\\phi}(\\mathbf{x}_n) \\right)^2 + \\frac{\\lambda}{2} \\mathbf{w}^T \\mathbf{w}.\n",
    "$$\n",
    "\n",
    "Для этого отнаследуйтесь от регрессора и переопределите его конструктор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdff4f7-c966-4fa7-b91d-c6f8db4cffce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeastSquareMod(LeastSquare):\n",
    "    def __init__(self, x, y, alpha):\n",
    "        x = ???\n",
    "        w = ???\n",
    "        self.??? = ???"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e294bf32-0f5c-4d74-998e-babf8b0cbddd",
   "metadata": {},
   "source": [
    "Подберите параметр регуляризации.\n",
    "Для этого постройте heat-карту, показывающую значение MSE в зависимости от порядка полинома $p$ и значения параметра регуляризации $\\lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57b382e-59e2-4aee-b077-df6538d410c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "powers = np.arange(2, 10)\n",
    "alphas = np.logspace(-6, 2, 8)\n",
    "err = np.zeros((len(powers), len(alphas)))\n",
    "errt = err.copy()\n",
    "regr = []\n",
    "for i, p in enumerate(powers):\n",
    "    for j, a in enumerate(alphas):\n",
    "        regressor = PolyDecorator(LeastSquareMod, p, x_train, y_train, a)\n",
    "        err[i][j] = ???\n",
    "        errt[i][j] = ???\n",
    "        regr???\n",
    "\n",
    "fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(2*7, 4))\n",
    "im0 = ax0.imshow(np.log10(err), cmap='viridis', aspect='auto')\n",
    "ax0.set(xlabel='$\\log_{10}(\\lambda)$', ylabel='Порядок полинома', title='Логарифм ошибки на обучающей выборке')\n",
    "ax0.set(xticks=range(len(alphas)), xticklabels=np.log10(alphas).round(decimals=1))\n",
    "ax0.set(yticks=range(len(powers)), yticklabels=powers)\n",
    "fig.colorbar(im0, ax=ax0)\n",
    "\n",
    "im1 = ax1.imshow(???)\n",
    "???\n",
    "\n",
    "fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(2*6, 4))\n",
    "ax0.hist(abs(regr[k](x_train) - ???))\n",
    "ax0.set(xlabel='Величина ошибки', ylabel='Количество', title='Обучающая выборка')\n",
    "ax1.hist(???)\n",
    "???\n",
    "\n",
    "k = ???\n",
    "print(f\"Порядок: {???}, параметр alpha: {???}, ошибка на тестовой выборке: {???}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d907291-3e1a-4a41-954a-cc28e659bc90",
   "metadata": {},
   "source": [
    "**Вопросы**:\n",
    "\n",
    "1. Какая модель (с регуляризацией или без) даёт лучшие результаты?\n",
    "1. Получилось ли достичь лучших результатов при меньшем порядке полинома? \n",
    "1. Наблюдалось ли переобучение модели, и было ли оно устранено введением регуляризации?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c816ac1d-8bba-41e0-892f-c9196bc52fb0",
   "metadata": {},
   "source": [
    "**Ответы:**\n",
    "\n",
    "1. ...\n",
    "1. ...\n",
    "1. ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
